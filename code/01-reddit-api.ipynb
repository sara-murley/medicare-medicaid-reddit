{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b01fab5-c6b4-4f38-8b3c-47a01ee2e5ef",
   "metadata": {},
   "source": [
    "# Reddit Data Collection: Medicare & Medicaid Posts\n",
    "\n",
    "## Overview\n",
    "This notebook collects Reddit posts related to Medicare and Medicaid from three subreddits:\n",
    "- r/Medicare  \n",
    "- r/Medicaid  \n",
    "- r/HealthInsurance  \n",
    "\n",
    "The goal is to construct a clean, reproducible corpus of Reddit posts for downstream text analysis and clustering, with a focus on understanding administrative burden and user experiences with public health insurance programs.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Collection Strategy\n",
    "Posts are retrieved using the Reddit API via the `praw` Python library. For each subreddit, the notebook:\n",
    "- Iterates backward in time using Reddit‚Äôs `new` listing\n",
    "- Applies **case-insensitive keyword filtering** (`\"medicare\"`, `\"medicaid\"`)\n",
    "- Collects a large enough sample to ensure broad temporal and topical coverage\n",
    "\n",
    "Rate limits are handled via conservative sleep intervals.\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "The notebook produces a single CSV file:\n",
    "\n",
    "**`cleaned_text_data.csv`**\n",
    "\n",
    "Each row corresponds to one Reddit post and includes:\n",
    "- Post metadata (subreddit, score, number of comments, timestamp)\n",
    "- Raw text (title + body)\n",
    "- Derived text features (character length, word count)\n",
    "- A cleaned text field suitable for TF‚ÄìIDF vectorization and clustering\n",
    "\n",
    "---\n",
    "\n",
    "## Reproducibility Notes\n",
    "- API credentials are **not hard-coded** and are loaded from environment variables\n",
    "- The notebook can be rerun end-to-end to regenerate the dataset\n",
    "- All preprocessing steps are explicit and documented to support transparency and replication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa349646-c971-4986-9e3d-c4e8833952ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import praw\n",
    "import prawcore\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0867620e-e11b-48ad-b5bc-2a42ae18cc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file from project root\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe217b1-1923-4175-a977-aef32de071f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cdb138-5948-4492-b7fa-17bcda08ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SUBREDDITS = [\"Medicare\", \"Medicaid\", \"HealthInsurance\"]\n",
    "KEYWORDS = [\"medicare\", \"medicaid\"]     \n",
    "TARGET_POSTS_PER_SUB = 1200             \n",
    "SLEEP_TIME = 1.5                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8c4dc0-a4da-4c48-9231-631c201d0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Scraping r/Medicare...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Scraping r/Medicaid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Scraping r/HealthInsurance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Scrape posts\n",
    "posts = []\n",
    "\n",
    "for sub in SUBREDDITS:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    collected = 0\n",
    "    last_timestamp = None\n",
    "\n",
    "    print(f\"\\nüîç Scraping r/{sub}...\")\n",
    "\n",
    "    while collected < TARGET_POSTS_PER_SUB:\n",
    "        params = {}\n",
    "        if last_timestamp:\n",
    "            params[\"before\"] = int(last_timestamp)\n",
    "\n",
    "        try:\n",
    "            batch = list(subreddit.new(limit=1000, params=params))\n",
    "        except prawcore.exceptions.TooManyRequests:\n",
    "            print(\"‚è≥ Rate limit hit ‚Äî sleeping 60s\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        for submission in tqdm(batch, leave=False):\n",
    "            last_timestamp = submission.created_utc\n",
    "\n",
    "            raw_text = f\"{submission.title} {submission.selftext}\"\n",
    "            raw_text_lower = raw_text.lower()\n",
    "\n",
    "            # keyword filter (case-insensitive)\n",
    "            if not any(k in raw_text_lower for k in KEYWORDS):\n",
    "                continue\n",
    "\n",
    "            posts.append({\n",
    "                \"id\": submission.id,\n",
    "                \"title\": submission.title,\n",
    "                \"text\": submission.selftext,\n",
    "                \"subreddit\": sub.lower(),\n",
    "                \"score\": submission.score,\n",
    "                \"num_comments\": submission.num_comments,\n",
    "                \"url\": submission.url,\n",
    "                \"created_utc\": submission.created_utc,\n",
    "                \"date\": datetime.fromtimestamp(submission.created_utc),\n",
    "            })\n",
    "\n",
    "            collected += 1\n",
    "            if collected >= TARGET_POSTS_PER_SUB:\n",
    "                break\n",
    "\n",
    "            time.sleep(SLEEP_TIME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7910a0-cdf4-4ab1-a4d9-31e6a4cb3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output DataFrame\n",
    "df = pd.DataFrame(posts).drop_duplicates(subset=\"id\")\n",
    "\n",
    "# Text features\n",
    "df[\"text_length\"] = df[\"text\"].str.len()\n",
    "df[\"word_count\"] = df[\"text\"].str.split().str.len()\n",
    "\n",
    "# Reorder columns to match your remembered file\n",
    "df = df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"title\",\n",
    "        \"text\",\n",
    "        \"subreddit\",\n",
    "        \"score\",\n",
    "        \"num_comments\",\n",
    "        \"url\",\n",
    "        \"created_utc\",\n",
    "        \"date\",\n",
    "        \"text_length\",\n",
    "        \"word_count\",\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "140c36c9-7f4c-4917-9638-e8f3d6aa134c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae64816e-3b0f-4e4a-b082-94c2a4b2b90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit\n",
      "medicaid           826\n",
      "medicare           717\n",
      "healthinsurance    122\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine Distribution Across Subreddits \n",
    "print(df[\"subreddit\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53158647-6d00-431e-8404-99e9256e2fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1qoihba</td>\n",
       "      <td>CenterWell scam??</td>\n",
       "      <td>Took my 81 year old mother to a Dr appointment...</td>\n",
       "      <td>medicare</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/medicare/comments/1qo...</td>\n",
       "      <td>1.769531e+09</td>\n",
       "      <td>2026-01-27 11:24:04</td>\n",
       "      <td>1190</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1qohpsb</td>\n",
       "      <td>Maryland, QMB with Medicare Advantage Plan, be...</td>\n",
       "      <td>My mom has a Medicare Advantage plan that cove...</td>\n",
       "      <td>medicare</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/medicare/comments/1qo...</td>\n",
       "      <td>1.769529e+09</td>\n",
       "      <td>2026-01-27 10:57:06</td>\n",
       "      <td>633</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1qog97w</td>\n",
       "      <td>insulin pens now $35 a month, so pen needles w...</td>\n",
       "      <td>Very happy that mom's Humalog pens are now onl...</td>\n",
       "      <td>medicare</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.reddit.com/r/medicare/comments/1qo...</td>\n",
       "      <td>1.769526e+09</td>\n",
       "      <td>2026-01-27 10:03:35</td>\n",
       "      <td>481</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1qnvkqv</td>\n",
       "      <td>Cigna Medicare Supplement Plan G 2026 Premium ...</td>\n",
       "      <td>There have been a lot of posts regarding the s...</td>\n",
       "      <td>medicare</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>https://www.reddit.com/r/medicare/comments/1qn...</td>\n",
       "      <td>1.769467e+09</td>\n",
       "      <td>2026-01-26 17:41:04</td>\n",
       "      <td>956</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1qnuing</td>\n",
       "      <td>Question about late enrollment penalties for p...</td>\n",
       "      <td>The situation is as follows:\\n\\nPerson born in...</td>\n",
       "      <td>medicare</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>https://www.reddit.com/r/medicare/comments/1qn...</td>\n",
       "      <td>1.769465e+09</td>\n",
       "      <td>2026-01-26 17:02:12</td>\n",
       "      <td>1047</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1qoihba                                  CenterWell scam??   \n",
       "1  1qohpsb  Maryland, QMB with Medicare Advantage Plan, be...   \n",
       "2  1qog97w  insulin pens now $35 a month, so pen needles w...   \n",
       "3  1qnvkqv  Cigna Medicare Supplement Plan G 2026 Premium ...   \n",
       "4  1qnuing  Question about late enrollment penalties for p...   \n",
       "\n",
       "                                                text subreddit  score  \\\n",
       "0  Took my 81 year old mother to a Dr appointment...  medicare      2   \n",
       "1  My mom has a Medicare Advantage plan that cove...  medicare      3   \n",
       "2  Very happy that mom's Humalog pens are now onl...  medicare      3   \n",
       "3  There have been a lot of posts regarding the s...  medicare      5   \n",
       "4  The situation is as follows:\\n\\nPerson born in...  medicare      1   \n",
       "\n",
       "   num_comments                                                url  \\\n",
       "0             0  https://www.reddit.com/r/medicare/comments/1qo...   \n",
       "1             2  https://www.reddit.com/r/medicare/comments/1qo...   \n",
       "2             3  https://www.reddit.com/r/medicare/comments/1qo...   \n",
       "3            14  https://www.reddit.com/r/medicare/comments/1qn...   \n",
       "4            11  https://www.reddit.com/r/medicare/comments/1qn...   \n",
       "\n",
       "    created_utc                date  text_length  word_count  \n",
       "0  1.769531e+09 2026-01-27 11:24:04         1190         215  \n",
       "1  1.769529e+09 2026-01-27 10:57:06          633         111  \n",
       "2  1.769526e+09 2026-01-27 10:03:35          481          95  \n",
       "3  1.769467e+09 2026-01-26 17:41:04          956         175  \n",
       "4  1.769465e+09 2026-01-26 17:02:12         1047         182  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4dedd9-a98f-46ca-8137-f598b9ed7a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved raw_reddit_data.csv with 1,665 posts\n"
     ]
    }
   ],
   "source": [
    "# Save file \n",
    "df.to_csv(\"../data/raw_reddit_data.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved raw_reddit_data.csv with {len(df):,} posts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
